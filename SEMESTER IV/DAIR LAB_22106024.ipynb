{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAIR LAB EVALUATION\n",
    "\n",
    "Name:     Sanidhya \\\n",
    "SID:    22106024 \\\n",
    "Branch: Computer Science Engineering (Data Science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Write Python code to tokenize the given text: \"Tokenization is the process of breaking text into smaller units such as words or sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'text', 'into', 'smaller', 'units', 'such', 'as', 'words', 'or', 'sentences', '.']\n",
      "Sentences: ['Tokenization is the process of breaking text into smaller units such as words or sentences.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Tokenization is the process of breaking text into smaller units such as words or sentences.\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Words:\", words)\n",
    "print(\"Sentences:\", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Provide an example of stemming using the Porter stemming algorithm. Stem the following words: \"running\", \"played\", \"jumps\", \"chased\", \"running\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'played', 'jumps', 'chased', 'running']\n",
      "Stemmed words: ['run', 'play', 'jump', 'chase', 'run']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = [\"running\", \"played\", \"jumps\", \"chased\", \"running\"]\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(word) for word in words]\n",
    "\n",
    "print(\"Original words:\", words)\n",
    "print(\"Stemmed words:\", stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform lemmatization on the same set of words using the WordNet lemmatizer. What are the lemmatized forms of these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original words: ['running', 'played', 'jumps', 'chased', 'running']\n",
      "Lemmatized words: ['running', 'played', 'jump', 'chased', 'running']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "words = [\"running\", \"played\", \"jumps\", \"chased\", \"running\"]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(\"Original words:\", words)\n",
    "print(\"Lemmatized words:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Compare and contrast the results of stemming and lemmatization. When would you choose one technique over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are both techniques used in natural language processing to reduce words to their base or root form. However, they differ in their approaches and the results they produce.\n",
    "\n",
    "Stemming:\n",
    "- Stemming involves removing suffixes from words to obtain their root form.\n",
    "- Stemmed words are not always real words and may not necessarily have semantic meaning.\n",
    "- Stemming tends to be faster and simpler compared to lemmatization.\n",
    "\n",
    "Lemmatization:\n",
    "- Lemmatization involves reducing words to their base or dictionary form (lemma) considering the word's meaning and context.\n",
    "- Lemmatized words are actual words and retain semantic meaning.\n",
    "- Lemmatization typically requires more computational resources compared to stemming.\n",
    "\n",
    "When to choose one technique over the other:\n",
    "\n",
    "1. Precision vs. Speed: If you prioritize precision and accuracy over speed, lemmatization is usually preferred. However, if you need faster processing and can tolerate some loss of precision, stemming might be more suitable.\n",
    "\n",
    "2. Language and Context: Stemming algorithms are language-dependent and may not work well with irregular forms or languages with complex morphologies. In contrast, lemmatization considers the word's meaning and context, making it more suitable for tasks where linguistic accuracy is crucial.\n",
    "\n",
    "3. Application and Domain: The choice between stemming and lemmatization also depends on the specific application and domain. For tasks like information retrieval or text classification, where speed is critical and minor inaccuracies can be tolerated, stemming might be sufficient. However, for tasks like language generation or sentiment analysis, where semantic accuracy is paramount, lemmatization is generally preferred.\n",
    "\n",
    "In summary, choose stemming when you need faster processing and can tolerate some loss of precision, while lemmatization is preferred for tasks requiring higher linguistic accuracy and semantic understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:\n",
    "#### You are tasked with building a basic indexing system for a small library. The library contains a collection of text documents, and users should be able to search for documents containing specific keywords.\n",
    "#### Implement an indexing system in Python that allows users to add documents to the collection and search for documents containing specific keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4]\n",
      "[2]\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "class Library:\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "\n",
    "    def add(self, document_id, text):\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word in self.index:\n",
    "                self.index[word].append(document_id)\n",
    "            else:\n",
    "                self.index[word] = [document_id]\n",
    "\n",
    "    def search(self, keyword):\n",
    "        if keyword in self.index:\n",
    "            return self.index[keyword]\n",
    "        else:\n",
    "            return \"Not found\"\n",
    "\n",
    "library = Library()\n",
    "\n",
    "# Add some documents\n",
    "library.add(1,\"The sun rises in the east and sets in the west\")\n",
    "library.add(2,\"Sunlight is essential for photosynthesis in plants\")\n",
    "library.add(3,\"The sun emits light and heat due to nuclear fusion reactions\")\n",
    "library.add(4,\"The sun is the biggest star in our solar system\")\n",
    "\n",
    "# Search for documents containing specific keywords\n",
    "print(library.search(\"sun\"))  \n",
    "print(library.search(\"photosynthesis\"))  \n",
    "print(library.search(\"earth\"))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
