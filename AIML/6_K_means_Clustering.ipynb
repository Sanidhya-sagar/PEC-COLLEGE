{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmpDFUs_2YFp"
      },
      "source": [
        "k-means clustering is an unsupervised machine learning algorithm that seeks to segment a dataset into groups based on the similarity of datapoints. An unsupervised model has independent variables and no dependent variables.\n",
        "\n",
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sCiZD8OE2Swc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy.random import uniform\n",
        "from sklearn.datasets import make_blobs\n",
        "import seaborn as sns\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhuP9fk5oNA"
      },
      "source": [
        "First generate a dataset of groups in 2-dimensional space. The sklearn.datasets function make_blobs creates groupings of 2-dimensional normal distributions, and assigns a label corresponding to the group said point belongs to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Iiairiuc5nE0"
      },
      "outputs": [],
      "source": [
        "# Create a dataset of 2D distributions\n",
        "centers = 5\n",
        "X_train, true_labels = make_blobs(n_samples=100, centers=centers, random_state=42)\n",
        "X_train = StandardScaler().fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObCEkfmk2WKy"
      },
      "source": [
        "To calculate the distances between a point and a dataset of points multiple times in this algorithm define a function that calculates Euclidean distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IOalkVn032BL"
      },
      "outputs": [],
      "source": [
        "def euclidean(point, data):\n",
        "    \"\"\"\n",
        "    Return euclidean distances between a point & a dataset\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.sum((point - data)**2, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kuOCnzI64CsM"
      },
      "outputs": [],
      "source": [
        "def most_common(lst):\n",
        "    \"\"\"\n",
        "    Return the most frequently occuring element in a list.\n",
        "    \"\"\"\n",
        "    return max(set(lst), key=lst.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzH1YyU14TNg"
      },
      "source": [
        "The k-means clustering algorithm is initialized with a value for k and a maximum number of iterations for finding the optimal centroid locations. If a maximum number of iterations is not considered when optimizing centroid locations, there is a risk of running an infinite loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0k3NJ1Wg06ob"
      },
      "outputs": [],
      "source": [
        "class KMeans:\n",
        "\n",
        "    def __init__(self, n_clusters=8, max_iter=300):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self, X_train):\n",
        "\n",
        "        # Initialize the centroids, using the \"k-means++\" method, where a random datapoint is selected as the first,\n",
        "        # then the rest are initialized w/ probabilities proportional to their distances to the first\n",
        "        # Pick a random point from train data for first centroid\n",
        "        self.centroids = [random.choice(X_train)]\n",
        "\n",
        "        for _ in range(self.n_clusters-1):\n",
        "            # Calculate distances from points to the centroids\n",
        "            dists = np.sum([euclidean(centroid, X_train) for centroid in self.centroids], axis=0)\n",
        "            # Normalize the distances\n",
        "            dists /= np.sum(dists)\n",
        "            # Choose remaining points based on their distances\n",
        "            new_centroid_idx = np.random.choice(range(len(X_train)), size=1, p=dists)[0]  # Indexed @ zero to get val, not array of val\n",
        "            self.centroids += [X_train[new_centroid_idx]]\n",
        "\n",
        "        # This method of randomly selecting centroid starts is less effective\n",
        "        # min_, max_ = np.min(X_train, axis=0), np.max(X_train, axis=0)\n",
        "        # self.centroids = [uniform(min_, max_) for _ in range(self.n_clusters)]\n",
        "\n",
        "        # Iterate, adjusting centroids until converged or until passed max_iter\n",
        "        iteration = 0\n",
        "        prev_centroids = None\n",
        "        while np.not_equal(self.centroids, prev_centroids).any() and iteration < self.max_iter:\n",
        "            # Sort each datapoint, assigning to nearest centroid\n",
        "            sorted_points = [[] for _ in range(self.n_clusters)]\n",
        "            for x in X_train:\n",
        "                dists = euclidean(x, self.centroids)\n",
        "                centroid_idx = np.argmin(dists)\n",
        "                sorted_points[centroid_idx].append(x)\n",
        "\n",
        "            # Push current centroids to previous, reassign centroids as mean of the points belonging to them\n",
        "            prev_centroids = self.centroids\n",
        "            self.centroids = [np.mean(cluster, axis=0) for cluster in sorted_points]\n",
        "            for i, centroid in enumerate(self.centroids):\n",
        "                if np.isnan(centroid).any():  # Catch any np.nans, resulting from a centroid having no points\n",
        "                    self.centroids[i] = prev_centroids[i]\n",
        "            iteration += 1\n",
        "\n",
        "    def evaluate(self, X):\n",
        "        centroids = []\n",
        "        centroid_idxs = []\n",
        "        for x in X:\n",
        "            dists = euclidean(x, self.centroids)\n",
        "            centroid_idx = np.argmin(dists)\n",
        "            centroids.append(self.centroids[centroid_idx])\n",
        "            centroid_idxs.append(centroid_idx)\n",
        "\n",
        "        return centroids, centroid_idxs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6AESWwu5gfr"
      },
      "source": [
        "Lets train and test it on our original dataset and see the results. We’ll keep our original method of plotting our data, by separating the true labels by color, but now we’ll additionally separate the predicted labels by marker style, to see how the model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "-xkjVXRs5HFr",
        "outputId": "54c1de7c-e8e8-4e05-e6ef-f01c75589b45"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit centroids to dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mcenters)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# View results\u001b[39;00m\n\u001b[0;32m      6\u001b[0m class_centers, classification \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mevaluate(X_train)\n",
            "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X_train)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train):\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Initialize the centroids, using the \"k-means++\" method, where a random datapoint is selected as the first,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# then the rest are initialized w/ probabilities proportional to their distances to the first\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Pick a random point from train data for first centroid\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids \u001b[38;5;241m=\u001b[39m [\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# Calculate distances from points to the centroids\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum([euclidean(centroid, X_train) \u001b[38;5;28;01mfor\u001b[39;00m centroid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\sksag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\random.py:369\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoice\u001b[39m(\u001b[38;5;28mself\u001b[39m, seq):\n\u001b[0;32m    368\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seq:\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
            "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "# Fit centroids to dataset\n",
        "kmeans = KMeans(n_clusters=centers)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "# View results\n",
        "class_centers, classification = kmeans.evaluate(X_train)\n",
        "sns.scatterplot(x=[X[0] for X in X_train],\n",
        "                y=[X[1] for X in X_train],\n",
        "                hue=true_labels,\n",
        "                style=classification,\n",
        "                palette=\"deep\",\n",
        "                legend=None\n",
        "                )\n",
        "plt.plot([x for x, _ in kmeans.centroids],\n",
        "         [y for _, y in kmeans.centroids],\n",
        "         '+',\n",
        "         markersize=10,\n",
        "         )\n",
        "plt.title(\"k-means\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
